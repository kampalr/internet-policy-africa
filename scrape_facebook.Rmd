---
title: 'Facebook Page Data Extraction using R: Prepared for Internet Policy Africa
  Meet March 1 2018'
author: "Richard Ngamita"
date: "March 01 2018"
twitter: "@ngamita"
output:
  pdf_document: default
  html_document: default
---

```{r}
# Note: At the moment, the only information that can be scraped from Facebook 
# is the content of public pages.
# To Scrape data from Facebooks API, 
# we'll go ahead and use the R packages for this. 
# To get access to the Facebook API, you need an OAuth code. 
# You can get yours going to the following URL: https://developers.facebook.com/tools/explorer

# Once you’re there:
# 1. Click on “Get Access Token”
# 2. Copy the long code (“Access Token”) and paste it here below, substituting the fake one I wrote:

```

    
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, error = FALSE, warning = FALSE)
```

```{r}
# List of packages required for this Twitter Search API data analysis
pkg <- c("Rfacebook")

# Check if packages are not installed and assign the
# names of the packages not installed to the variable new.pkg
new.pkg <- pkg[!(pkg %in% installed.packages())]

# If there are any packages in the list that aren't installed,
# install them
if (length(new.pkg)) {
    install.packages(new.pkg, repos = "http://cran.rstudio.com")
}
# Load libraries for accessing the Twitter search API. 
library(Rfacebook)

```

```{r }
# extract Facebook  data. Add the long Access Token you just got from developers.facebook.com page. 
fb_oauth = 'EAACEdEose0cBAHWQXktKdNUZAmiFbmlnbGKQwmmlrE9tiMw1iZBxoIwHcwbZCTr38FQoYsyOpbcsxGGqhoiIJl1fhpDlbZCeuwWkguuQu1E1vyDIl5yRuJZBozNci44ZBdPNPHZAdBZAGzHwSKPD7Iq5GBySrlkB0hjcKLZBSkUfKYlLluLYkFr658o0Jtu75eNc2CGaUwf5POgZDZD'
```

```{r }
# Now get the user details you're logged in as. 
getUsers("me", token=fb_oauth, private_info=TRUE)

# Does it return your Facebook public information? Yes? Then we’re ready to go. See also ?fbOAuth for
# information on how to get a long-lived OAuth token.

```

```{r }
# The following line downloads the ~200 most recent posts on the facebook page of BBC Africa
page <- getPage("bbcafrica", token=fb_oauth, n=20, reactions=TRUE, api="v2.9") 
```

```{r }
# What information is available for each of these posts?
page[1,]
```


```{r }
# page[which.max(page$likes_count),]
page[which.max(page$likes_count),]
page[which.max(page$comments_count),]
page[which.max(page$shares_count),]

```

```{r }
# save extracted data to csv file
# Windows compute d:/internet_policy_fb.csv or right path to writable drive. 
write.csv(page[1:20,], "~/internet_policy_fb.csv")
page[1:20,]
```